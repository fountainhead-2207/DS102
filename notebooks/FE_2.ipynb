{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0919cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7338ec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'/home/check/DATA/university/yr3, hk1/DS102 - ML for Statistic/Đồ án/goodread/DS102/DATA/'\n",
    "GOLD_FILE = data_path + \"gold/v1/gold_1.csv\"          # Thay bằng tên file gold của bạn (gold_2.csv, ...)\n",
    "OUTPUT_FOLDER =data_path + \"gold/v1\"            \n",
    "TRAIN_CSV = \"train_1.csv\"\n",
    "TEST_CSV = \"test_1.csv\"\n",
    "\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5de6b4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(GOLD_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "234e1a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (2058, 26)\n",
      "Unique books: 319 (ước lượng)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original shape: {df.shape}\")\n",
    "print(f\"Unique books: {df['title'].nunique()} (ước lượng)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1d2c0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['book_id'] = df['title'].astype(str).str.strip() + \"|||\" + df['author'].astype(str).str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8fe79b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "df['review_sentiment'] = df['review_text'].fillna('').astype(str).apply(\n",
    "    lambda x: sia.polarity_scores(x)['compound']\n",
    ")\n",
    "df['review_length'] = df['review_text'].fillna('').astype(str).apply(lambda x: len(x.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2490dc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['Commercial_success', 'Popular_success', 'Critical_success']\n",
    "y = df[target_cols]\n",
    "X_with_id = df.drop(columns=target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7281068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 1641 (books: 273)\n",
      "Test samples:  417 (books: 69)\n",
      "No leakage: True\n"
     ]
    }
   ],
   "source": [
    "groups = df['book_id']\n",
    "splitter = GroupShuffleSplit(test_size=0.2, n_splits=1, random_state=42)\n",
    "train_idx, test_idx = next(splitter.split(X_with_id, y, groups=groups))\n",
    "\n",
    "X_train_full = X_with_id.iloc[train_idx].copy()\n",
    "X_test_full = X_with_id.iloc[test_idx].copy()\n",
    "y_train = y.iloc[train_idx].copy()\n",
    "y_test = y.iloc[test_idx].copy()\n",
    "\n",
    "print(f\"Train samples: {len(X_train_full)} (books: {X_train_full['book_id'].nunique()})\")\n",
    "print(f\"Test samples:  {len(X_test_full)} (books: {X_test_full['book_id'].nunique()})\")\n",
    "print(f\"No leakage: {len(set(X_train_full['book_id']) & set(X_test_full['book_id'])) == 0}\")\n",
    "\n",
    "X_train = X_train_full.drop(columns=['book_id'])\n",
    "X_test = X_test_full.drop(columns=['book_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fee1c41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform(X):\n",
    "    return np.log1p(X)\n",
    "\n",
    "log_transformer = FunctionTransformer(log_transform)\n",
    "\n",
    "num_normal_cols = [\n",
    "    'year', 'publication_year', 'total_weeks', 'best_rank', 'worst_rank', 'mean_rank',\n",
    "    'debut_rank', 'average_rating', 'rating', 'is_expert',\n",
    "    'review_sentiment', 'review_length'\n",
    "]\n",
    "\n",
    "skew_cols = [\n",
    "    'Units_Sold', \n",
    "    'Gross_Sales', \n",
    "    'Sale_Price', \n",
    "    'Sales_Rank',     \n",
    "    'ratings_count',\n",
    "    'n_votes'\n",
    "]\n",
    "\n",
    "\n",
    "author_rating_categories = [['Novice', 'Intermediate', 'Famous', 'Excellent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c995a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('num_normal', StandardScaler(), num_normal_cols),\n",
    "    ('num_skew', Pipeline(steps=[\n",
    "        ('log', log_transformer),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]), skew_cols),\n",
    "    ('author_rating_ordinal', OrdinalEncoder(categories=author_rating_categories), ['Author_Rating']),\n",
    "    ('genre_onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), ['Genre']),\n",
    "    ('desc_tfidf', TfidfVectorizer(max_features=2000, stop_words='english'), 'description'),\n",
    "    ('review_tfidf', TfidfVectorizer(max_features=3000, stop_words='english', ngram_range=(1,2)), 'review_text')\n",
    "], remainder='drop', sparse_threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "935e0ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang fit preprocessor trên train...\n",
      "Đang transform test...\n"
     ]
    }
   ],
   "source": [
    "print(\"Đang fit preprocessor trên train...\")\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "print(\"Đang transform test...\")\n",
    "X_test_processed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ed4ba80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tạo tên feature thủ công...\n"
     ]
    }
   ],
   "source": [
    "print(\"Đang tạo tên feature thủ công...\")\n",
    "\n",
    "feature_names = num_normal_cols.copy()\n",
    "feature_names += [f\"log_{col}\" for col in skew_cols]\n",
    "feature_names += ['Author_Rating_ordinal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "31f97ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genre one-hot\n",
    "genre_categories = preprocessor.named_transformers_['genre_onehot'].categories_[0]\n",
    "genre_dropped = preprocessor.named_transformers_['genre_onehot'].drop_idx_\n",
    "if genre_dropped is not None:\n",
    "    genre_kept = [cat for i, cat in enumerate(genre_categories) if i != genre_dropped]\n",
    "else:\n",
    "    genre_kept = genre_categories[1:]\n",
    "feature_names += [f\"Genre_{cat}\" for cat in genre_kept]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "690d0842",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_vocab = preprocessor.named_transformers_['desc_tfidf'].get_feature_names_out()\n",
    "review_vocab = preprocessor.named_transformers_['review_tfidf'].get_feature_names_out()\n",
    "\n",
    "feature_names += [f\"desc_{word}\" for word in desc_vocab]\n",
    "feature_names += [f\"review_{word}\" for word in review_vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ab4048dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features: 5021\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total features: {len(feature_names)}\")\n",
    "assert len(feature_names) == X_train_processed.shape[1], \"Số cột không khớp!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0462eaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "train_df = pd.DataFrame(\n",
    "    X_train_processed.toarray() if hasattr(X_train_processed, \"toarray\") else X_train_processed,\n",
    "    columns=feature_names,\n",
    "    index=X_train.index\n",
    ")\n",
    "train_df[target_cols] = pd.DataFrame(y_train.values, columns=target_cols, index=y_train.index)\n",
    "\n",
    "# Test\n",
    "test_df = pd.DataFrame(\n",
    "    X_test_processed.toarray() if hasattr(X_test_processed, \"toarray\") else X_test_processed,\n",
    "    columns=feature_names,\n",
    "    index=X_test.index\n",
    ")\n",
    "test_df[target_cols] = pd.DataFrame(y_test.values, columns=target_cols, index=y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a958c34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hoàn tất lưu file!\n",
      "   → /home/check/DATA/university/yr3, hk1/DS102 - ML for Statistic/Đồ án/goodread/DS102/DATA/gold/v1/train_1.csv\n",
      "     Shape: 1641 rows × 5024 columns\n",
      "   → /home/check/DATA/university/yr3, hk1/DS102 - ML for Statistic/Đồ án/goodread/DS102/DATA/gold/v1/test_1.csv\n",
      "     Shape: 417 rows × 5024 columns\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(OUTPUT_FOLDER, TRAIN_CSV)\n",
    "test_path = os.path.join(OUTPUT_FOLDER, TEST_CSV)\n",
    "\n",
    "train_df.to_csv(train_path, index=False)\n",
    "test_df.to_csv(test_path, index=False)\n",
    "\n",
    "print(\"\\nHoàn tất lưu file!\")\n",
    "print(f\"   → {train_path}\")\n",
    "print(f\"     Shape: {train_df.shape[0]} rows × {train_df.shape[1]} columns\")\n",
    "print(f\"   → {test_path}\")\n",
    "print(f\"     Shape: {test_df.shape[0]} rows × {test_df.shape[1]} columns\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
